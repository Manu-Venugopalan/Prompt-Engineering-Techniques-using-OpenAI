# üß† Prompt Engineering for AI Tasks
![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)
![Model](https://img.shields.io/badge/Model-FinBERT-yellow.svg)
![Model](https://img.shields.io/badge/Model-OpenAI-yellow.svg)
![Tech](https://img.shields.io/badge/Technique-ZeroShot%20|%20FewShot%20|%20CoT-orange.svg)
![Issues](https://img.shields.io/github/issues/your-username/your-repo.svg)
![Stars](https://img.shields.io/github/stars/your-username/your-repo.svg)

Prompt engineering is a core technique in working with modern large language models (LLMs) like GPT, LLaMA, Claude, and FinBERT. It involves crafting the right instructions (prompts) to guide the model toward generating the most accurate and contextually appropriate responses for a given task.

---

### üìò Prompt Engineering Techniques (With Examples)

| Technique                       | Description                                                                                                                                         | Example                                                                                                                                                                                                         |
| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Zero-shot prompting**         | Asking the model to complete a task with no prior examples or context. Useful when the model is already well-trained on a broad range of knowledge. | **Prompt:**<br>‚ÄúClassify the following sentence as positive, neutral, or negative: ‚ÄòThe market closed higher today.‚Äô‚Äù<br>**Expected Output:**<br>Positive                                                       |
| **Few-shot prompting**          | Providing a few annotated examples before asking the model to perform a similar task. Enhances performance when training data is scarce.            | **Prompt:**<br>‚ÄúClassify the sentiment:<br>1. ‚ÄòThe stock fell sharply.‚Äô ‚Üí Negative<br>2. ‚ÄòCompany revenue grew.‚Äô ‚Üí Positive<br>3. ‚ÄòDividend remained unchanged.‚Äô ‚Üí‚Äù<br>**Expected Output:** Neutral             |
| **Chain-of-thought prompting**  | Encouraging the model to think step-by-step before providing the final answer. Useful for tasks requiring logical reasoning or calculations.        | **Prompt:**<br>‚ÄúIs 738 divisible by 3? First, sum the digits: 7+3+8=18. Is 18 divisible by 3?‚Äù<br>**Expected Output:** Yes, 738 is divisible by 3.                                                              |
| **Instruction-based prompting** | Giving explicit instructions in natural language. Best for information extraction, summarization, or formatting tasks.                              | **Prompt:**<br>‚ÄúExtract all financial entities and amounts from the text.‚Äù<br>‚ÄúBarclays invested ¬£50 million in renewable energy.‚Äù<br>**Expected Output:**<br>{ "Entity": "Barclays", "Amount": "¬£50 million" } |
| **Role prompting**              | Assigning a specific role or persona to the model to influence the style or domain knowledge of the response.                                       | **Prompt:**<br>‚ÄúYou are a financial advisor. Recommend an investment plan for a risk-averse client in retirement.‚Äù<br>**Expected Output:**<br>A balanced fund or low-risk bond portfolio.                       |
| **Output formatting**           | Asking the model to respond in a particular format (JSON, list, table, etc.) to aid downstream processing.                                          | **Prompt:**<br>‚ÄúSummarize the key investment risks. Respond in bullet points.‚Äù<br>**Expected Output:**<br>- Market volatility<br>- Inflation<br>- Liquidity risk                                                |
| **Prompt tuning (advanced)**    | Optimizing soft prompt tokens using a training dataset. Used in enterprise-level applications to fine-tune model behavior.                          | **Tools Used:** PEFT, LoRA, or SoftPrompting libraries.                                                                                                                                                         |

---

### ‚úÖ Real-World Applications in This Project

This repository demonstrates how prompt engineering is applied to tasks in the financial services domain, using models like FinBERT and GPT:

* **Text Classification (Zero/Few-shot):** Classify financial statements into labels like `ObjectivesAndNeeds`, `Assets`, `Outgoings`, etc.
* **Information Extraction (Instruction-based):** Extract data points like investment amount, institution name, and client goals from conversations.
* **Summarization (Role-based):** Generate personalized meeting summaries from advisor-client interactions.
* **Risk Profiling (Chain-of-thought):** Guide the model to assess financial risk tolerance using reasoning prompts.

---

### üöÄ Technologies Used

* **LLMs:** GPT-4, FinBERT
* **Prompting Frameworks:** LangChain, OpenAI API
* **Data:** Annotated Atlas files and unannotated Arla transcripts from financial conversations
* **Environment:** Python 3.8+, Transformers, Hugging Face Datasets


### üìà Future Work

* Integrate prompt-based evaluation for performance benchmarking
* Incorporate RAG (Retrieval-Augmented Generation) with prompt verification
* Extend support for multilingual financial datasets

---


